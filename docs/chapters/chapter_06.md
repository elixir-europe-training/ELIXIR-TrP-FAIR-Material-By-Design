!!! success "Learning Outcomes"

     By the end of this session, learners will be able to:  
      
    - Explain why video materials should follow FAIR principles and identify key challenges in doing so  
    - Evaluate how FAIR a given video is, using real examples
    - Apply minimum FAIR-by-design practices when creating or sharing training videos 
    - Generate and use transcripts or captions to enhance accessibility and interoperability
  


## 6.1 Presentation
Here you can find the presentation for this session:

<iframe src="https://docs.google.com/presentation/d/1FnBrgXXmSBMSVXlVohaGQeETwO2FR2lX/preview" width="640" height="360" allow="autoplay"></iframe>

The full presentation can be downloaded as a pdf by clicking [here](https://docs.google.com/presentation/d/1FnBrgXXmSBMSVXlVohaGQeETwO2FR2lX/export?format=pdf).


## 6.2 Why FAIR video materials matter
Video is one of the most powerful ways to enhance learning, but only if it can be found, accessed, reused, and understood by others.
Making your video materials FAIR ensures that the effort you invest in creating them continues to have impact long after the initial training. 

!!! question "Reflection"

    Before we dive deeper, take a moment to reflect:  
      
      - Have you used / are you planning to use video material in your training?  
      - What kind of video material? (e.g., recorded lectures, interviews, demonstrations, or animations)  
      - Why or why not?   

### Why video media is a great tool for learning
Video media is great for enhancing & contextualizing learning! Some advantages include:  
  
- Improved retention and understanding:  combining visual and auditory information engages multiple senses ‚Üí dual coding theory (1, 2)
- Supports flexible, self-paced learning: learners can pause, rewind, or rewatch segments at their own pace (3, 4) 
- Enables asynchronous learning: learners access materials anytime, anywhere  
- Provides authentic demonstrations: e.g. when teaching lab techniques, workflows, or software use  
- Increases accessibility and inclusion: captions, transcripts, and translations make content more widely usable  

  
### Types of video materials that can be made FAIR
  
There are many ways to use video as a training resource, for example: voiceovers added to slides or presentations, screen recordings showing workflows/coding/software demonstrations, interviews with experts or practitioners, lecture recordings or seminars, animations and explainer videos, hands-on demonstrations in labs or fieldwork settings. All of these can be made FAIR!  

Let's now have a look at what it takes to FAIRify video material: 

!!! note "Exercise"

    Find a short video (for example on YouTube, Protocols.io, Zenodo, or another platform) that you might want to include in your own course, or use one of two sample videos that can be found [here](https://www.youtube.com/watch?v=VUGsZgQaAZs) and [here](https://www.protocols.io/view/video-protocol-for-sorting-drosophila-pupae-n2bvjx8nwlk5/v1). For your chosen video, take 5‚Äì10 minutes to assess:  
    
    - **Findable** ‚Üí Is it hosted on a trusted platform? Does it have a DOI or persistent identifier?
    - **Accessible** ‚Üí Is the access type and language defined? Can the video or transcript be downloaded? 
    - **Interoperable** ‚Üí Are there captions or transcripts? Is it in a standard format (e.g. .mp4, .mov)?
    - **Reusable** ‚Üí Is there a clear license? Are contributors and tools properly attributed? Is there versioning information?

    Document your findings in the [**Checklist for minimally FAIR video material**](https://docs.google.com/document/d/e/2PACX-1vTAvSqdNhrO_ZNsRvzPSulFxucFkbNN7UvnC1oFvyFZtG4H0wZWBgcGFWct2ynB8eFA3UwDeAehT_Xb/pub)

!!! question "Reflection"

    After the exercise, take a moment to reflect:  
    
    - Was the video material you chose FAIR?  
    - How easy would it be for you to reuse this material?   
    - If not easy: what information would you need to make reuse easier?  

      
### Why FAIR video materials matter  
Making your video materials FAIR increases their long-term value and educational impact:  
  
- It makes them easy to locate  
- It supports asynchronous learning when they can be viewed or downloaded anytime, anywhere   
- It enables using them across platforms and tools  
- It allow others to legally adapt or remix them  
- It ensures they remain available and understandable over time  

In short: **FAIR video = more impact from the effort you put into creating it**  
By sharing your training videos in a FAIR way, you amplify their reach, support diverse learners, and contribute to a more open and connected scientific training ecosystem.


## 6.3 Barriers to creating FAIR video materials 
Making video materials FAIR can be highly rewarding ‚Äî but it‚Äôs not always straightforward. There are practical, technical, and even ethical challenges that educators and trainers often face.  

!!! question "Reflection"

    Before we look at common barriers, take a moment to reflect:  
    What‚Äôs the biggest barrier for you in using and FAIRifying video material? Is it related to technology, time, or something else?

Below are some of the most common obstacles encountered when creating or sharing FAIR video materials:

| **Barrier** | **Description** |
|--------------|------------------|
| **Time & Resources** | Creating, editing, and annotating videos takes planning and effort. |
| **Technical Skills** | Recording, editing, adding metadata, and creating captions require some know-how. |
| **Knowledge Gaps** | Limited awareness of FAIR video practices or suitable hosting platforms. |
| **Infrastructure** | Not all organizations have repositories or tools for storing videos with FAIR metadata. |
| **Licensing & Permissions** | Confusion about copyright, reuse rights, and privacy when sharing video content. |
| **AI & Ethics** | Emerging tools (e.g., for transcription or editing) raise questions about bias, transparency, and attribution. |
| **File Size & Storage Limits** | High-quality video files are large, making them harder to host on institutional repositories or platforms like Zenodo (often limited to 50 GB per upload). |
| **Metadata Complexity** | Video materials often need multiple layers of metadata (e.g., author, content, format, transcript, licensing), and it‚Äôs not always clear where or how to include these. |

Even though these barriers exist, many can be overcome with planning, collaboration, and the right tools. In the next section, we‚Äôll look at practical steps and minimum FAIR-by-design practices to help make your video materials more FAIR without requiring expert-level skills.  
  

## 6.4 AI and FAIR video material 

### A workflow for making FAIR video material with the use of AI  

A potential way to mitigate some of the barriers to FAIR video materials is to use AI tools at different stages of video creation. The workflow below illustrates which tools, some of which use AI, can support each stage:   

![](../../assets/images/06-fair-video-material-ai.png)<!-- style="width: 550px;" -->  

As the workflow illustrates, AI tools can help overcome several common barriers in creating FAIR video materials, from generating scripts to editing, transcribing, and hosting videos. While AI can speed up production and reduce workload, it‚Äôs important to remember that using AI does not automatically make content FAIR. For example, an AI-generated transcript may improve accessibility, but if it is not properly formatted, licensed, or shared with metadata, it will not be findable or reusable. Likewise, AI platforms may store outputs in proprietary formats or behind authentication walls, limiting accessibility and interoperability. Ensuring FAIRness thus requires deliberate steps by the creator, such as applying open licenses, adding persistent identifiers, using open formats, and providing rich, structured metadata. 

!!! question "Reflection"
     
     Use AI with caution!  
     
     - Is AI-generated content FAIR?  
     - How can you ensure quality and accuracy?  
     - How might AI affect creativity and learner engagement?  
     - How should we credit AI contributions?   

### Indicating AI contributions  

If you do decide to use AI tools in your video creation process, it is important to indicate its contribution properly to ensure transparency, maintain trust, and support FAIR principles. Properly stating AIs contribution makes the provenance of your materials understandable for both humans and machines, and helps others to responsibly reuse or adapt your video content.    
  
General guidelines for indicating AI contribution:   

| **Aspect** | **Guidelines / Examples** |
|------------|---------------------------|
| **Crediting AI** | For AI tools that had a creative or technical role: *‚ÄúScript generated with ChatGPT (OpenAI, 2025)‚Äù* |
| **Describing the role of AI** | Explain how an AI tool was used, e.g., *‚ÄúVoiceover synthesized using Microsoft Azure TTS‚Äù* |
| **Crediting AI in metadata or end credits** | *‚ÄúVideo created by [Name], 2025. Script drafted with ChatGPT (OpenAI, version x.x). Captions generated using Whisper (OpenAI). Edited in CapCut.‚Äù* |
| **Citing AI in reference lists / FAIR records** | *Luijten, I. (2025). Creating FAIR video materials [Video]. Script generated with ChatGPT (OpenAI). Captions via Whisper (OpenAI). Zenodo. https://doi.org/10.xxxx/zenodo.xxxxx* |
| **Licensing AI-generated content** | License with CC BY or CC BY-SA to allow reuse with attribution. State if remixing or AI reuse is permitted. |


### Adding transcripts to videos: WhisperAI

One essential step in FAIRifying video training materials is adding captions or a transcript, because it transforms the spoken content into machine-readable and searchable text. This improves **findability**, as search engines and repositories can index the text and help others discover your content. It also enhances **accessibility**, ensuring that people with hearing impairments or those who prefer reading can still engage with the material. In addition, transcripts and captions promote **interoperability** by allowing the content to be reused across different platforms, formats, or languages. Finally, they increase **reusability**, since the text can be cited, translated, remixed, or integrated into other learning materials, all while preserving the original meaning and context.  
<br>  
The following exercise is designed to give you hands-on practice with generating transcripts and captions. There are three levels of difficulty available, but for this course, we recommend you complete Level 1, which is suitable for beginners and covers the core skills needed to make your videos FAIR by adding a transcript or caption.  

<div style="background-color:lightgreen; padding-top:7px; padding-bottom:1px; padding-left:15px; border-radius:10px;margin-bottom:10px;">
<b>Easy technical level</b><br>
Basic computer skills required
</div>

<div style="background-color:#F8C471; padding-top:7px; padding-bottom:1px; padding-left:15px; border-radius:10px;margin-bottom:10px;">
<b>Intermediate technical level</b><br>
Some experience installing and using desktop applications 
</div>

<div style="background-color:#D98880; padding-top:7px; padding-bottom:1px; padding-left:15px; border-radius:10px;margin-bottom:10px;">
<b>Advanced technical level</b><br>
Intermediate knowledge of GitHub and using the terminal required
</div>
<br>  
  
For this exercise, you'll need a short video. You can download [our sample video](https://drive.google.com/file/d/1TdwvG0R5_UGFCE9jAOZXjloCoVk1dfoz/view?usp=sharing) from the course website or record a 1-2 minute video on your smartphone or laptop to use.
!!! warning
    Ensure you do not record anyone without their permission!
    
    
!!! note "Using the SciLifeLab serve instance of Whisper (easy)"

     1. Go to https://whisper-ai.serve.scilifelab.se  
     2. Upload your video file  
     3. Select the desired output format(s):  
          .txt for a plain transcript  
          .srt for caption files  
     6. Submit the file for processing  
     7. When transcription is complete, your output files will automatically download to your computer  

!!! note "Using an on-device GUI such as Whisper Transcription (intermediate)"

     1. Download the Whisper Transcription app (developed by Good Snooze) from the Mac App Store  
     2. In the app, download the Small Whisper model for faster performance  
     3. Open your video or audio file in the app to start transcription  
     4. Once completed, export the results as:  
          .srt for captions, or  
          .txt for transcript text  

!!! note "Installing your own local instance of Whisper (advanced)"

    1. Install Whisper directly from GitHub: `pip install -U openai-whisper`, or from the repository at [https://github.com/openai/whisper](https://github.com/openai/whisper)  
    2. Install ffmpeg if not already available:  
       - macOS: `brew install ffmpeg`  
       - Windows: `choco install ffmpeg`  
    3. Save your transcription script as `thecode.py` in a text editor  

    ??? abstract "Transcription script"

        ```python
        import whisper  

        model = whisper.load_model("base")    
        result = model.transcribe("audio.mp3")    

        with open("transcript.txt", "a") as f:
            print(result["text"], file=f)
        ```

        **Variables:**  
        - `base` ‚Äî model size (small, medium, etc.)  
        - `audio.mp3` ‚Äî your audio file (.m4a, .wav, .flac)  
        - `transcript.txt` ‚Äî name of your output transcript  

    4. Place your audio file (e.g. `audio1234.mp3`) in the same directory  
    5. Open a terminal and navigate to that folder: `cd path/to/your/files`  
    6. Run the script: `python3 thecode.py`  
    7. Wait for transcription to complete ‚Äî your output will appear in the same directory      


!!! question "Reflection"
     
     When you are finished transcription, inspect the transcript and answer the following:    
     
     - Is it accurate? 
     - Is it usable?
     - How does this help me achieve FAIR learning aims?  


## 6.5 Adding FAIR video & transcript to your sample course

In this final exercise, you will practice publishing your own FAIR-by-design training video. Following the basic guidelines below, add your video and its transcript or captions to your sample course page. This step helps make your learning material more FAIR by ensuring that your video content is well-described, openly shared, and accessible to all learners.

!!! note "Using OpenEdx"

     1. Upload your video to a FAIR-friendly, openly accessible platform such as YouTube, Zenodo, or Figshare. Make sure the video has a descriptive title, license, and metadata.  
     2. If your video includes captions or a transcript file (.srt or .txt), upload that as well and link it in your course content.    
     3. Go to your sample course on [https://sandbox.openedx.org/]( https://sandbox.openedx.org/)  
     6. Click on 'view course in: Studio' in the top right corner. You will be taken to course outline. 
     7. Create a new section or unit, rename it to something like Training Video
     8. Add a subsection and a unit where the video will appear
     9. Under 'Add a new component' click 'Video'
     10. Copy paste the URL for you video 
     11. If you have a transcript, click 'Transcripts' and upload your .srt file 
     12. Under 'License' select the Creative Commons license of your choice
     13. Click 'Save' and check that your video plays correctly and that the transcript link works
     14. Click Publish to make your course unit visible  

     You‚Äôve embedded your FAIR video and provided a transcript and license to improve findability, accessibility, and reusability.  
     
 !!! note "Using GitHub and LiaScript"

     1. Upload your video to a FAIR-friendly, openly accessible platform such as YouTube, Zenodo, or Figshare.  
        Make sure the video has a descriptive title, license, and metadata.  
     2. Upload your transcript file (`.txt` or `.md`) to your GitHub repository or another accessible public location.  
     3. Go to your course repository created from the [training material template](https://github.com/vibbits/training_material_template).  
     4. Open the file `README.md` in your browser or local editor.  
     5. Embed your video in Markdown. LiaScript supports simple Markdown video embedding. Add something like:  
        ```markdown
        ## üé• Training Video

        ![Video](https://img.youtube.com/vi/yourvideoid/0.jpg)  
        [Watch on YouTube](https://www.youtube.com/watch?v=yourvideoid)
        ```
        Alternatively, embed directly using HTML:  
        ```html
        <iframe width="800" height="450" src="https://www.youtube.com/embed/yourvideoid" frameborder="0" allowfullscreen></iframe>
        ```

     6. Add your transcript below the video:  
        ```markdown
        **Transcript:**  
        [Download transcript (.txt)](transcript.txt)
        ```
        Or include a short excerpt for learners to preview:  
        ```markdown
        > ‚ÄúWelcome to this FAIR video tutorial‚Ä¶‚Äù
        ```

     7. Commit and save your changes.  
     8. Open your course through [https://liascript.github.io/](https://liascript.github.io/) using the **raw URL** of your updated `README.md`.  
     9. Refresh your browser to see your embedded video and transcript displayed in the LiaScript course page.  

     You‚Äôve now embedded a FAIR video and transcript in your LiaScript course ‚Äî ensuring your content is accessible, shareable, and reusable.



## Citations
1.	Paivio A (2009) Mental Representations: A dual coding approach, Oxford Psychology Series.  https://doi.org/10.1093/acprof:oso/9780195066661.001.0001  
2.	Mayer RE (2009) Multimedia Learning. 2nd ed. Cambridge University Press. https://doi.org/10.1017/CBO9780511811678  
3.	Guo P, Kim J,  Rubin R. (2014) How video production affects student engagement: An empirical study of MOOC videos. L@S '14: Proceedings of the first ACM conference on Learning @ scale conference 41-50. https://doi.org/10.1145/2556325.2566239  
4. Zhang D, Zhou L, Briggs RO, Nunamaker JF (2006) Instructional video in e-learning: Assessing the impact of interactive video on learning effectiveness. Information & Management 43(1): 15-27, https://doi.org/10.1016/j.im.2005.01.004   








